{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "    \n",
    "MODEL_PATH = \"models/recognition/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "height = 28\n",
    "width = 28\n",
    "channels = 1\n",
    "n_inputs = height * width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "X_train = X_train.astype(np.float32).reshape(-1, n_inputs) / 255.0\n",
    "X_test = X_test.astype(np.float32).reshape(-1, n_inputs) / 255.0\n",
    "y_train = y_train.astype(np.int32)\n",
    "y_test = y_test.astype(np.int32)\n",
    "nb_samples_taken = 2000\n",
    "X_train = X_train[:nb_samples_taken]\n",
    "y_train = y_train[:nb_samples_taken]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "conv1_fmaps = 32\n",
    "conv1_ksize = 3\n",
    "conv1_stride = 1\n",
    "\n",
    "conv2_fmaps = 64\n",
    "conv2_ksize = 3\n",
    "conv2_stride = 2\n",
    "\n",
    "conv3_fmaps = 128\n",
    "conv3_ksize = 3\n",
    "conv3_stride = 2\n",
    "\n",
    "pool3_fmaps = conv3_fmaps\n",
    "\n",
    "n_fc1 = 128\n",
    "n_outputs = 10\n",
    "\n",
    "with tf.name_scope(\"inputs\"):\n",
    "    X = tf.placeholder(tf.float32, shape=[None, n_inputs], name=\"X\")\n",
    "    X_reshaped = tf.reshape(X, shape=[-1, height, width, channels])\n",
    "    y = tf.placeholder(tf.int32, shape=[None], name=\"y\")\n",
    "\n",
    "conv1 = tf.layers.conv2d(X_reshaped, filters=conv1_fmaps, kernel_size=conv1_ksize,\n",
    "                         strides=conv1_stride, padding=\"SAME\",\n",
    "                         activation=tf.nn.relu, name=\"conv1\")\n",
    "conv2 = tf.layers.conv2d(conv1, filters=conv2_fmaps, kernel_size=conv2_ksize,\n",
    "                         strides=conv2_stride, padding=\"SAME\",\n",
    "                         activation=tf.nn.relu, name=\"conv2\")\n",
    "conv3 = tf.layers.conv2d(conv2, filters=conv3_fmaps, kernel_size=conv3_ksize,\n",
    "                         strides=conv3_stride, padding=\"SAME\",\n",
    "                         activation=tf.nn.relu, name=\"conv3\")\n",
    "\n",
    "with tf.name_scope(\"pool3\"):\n",
    "    pool3 = tf.nn.max_pool(conv3, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"VALID\")\n",
    "    pool3_flat = tf.reshape(pool3, shape=[-1, pool3_fmaps * 3 * 3])\n",
    "\n",
    "with tf.name_scope(\"fc1\"):\n",
    "    fc1 = tf.layers.dense(pool3_flat, n_fc1, activation=tf.nn.relu, name=\"fc1\")\n",
    "\n",
    "with tf.name_scope(\"output\"):\n",
    "    logits = tf.layers.dense(fc1, n_outputs, name=\"output\")\n",
    "    Y_proba = tf.nn.softmax(logits, name=\"Y_proba\")\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=y)\n",
    "    loss = tf.reduce_mean(xentropy)\n",
    "    loss_ = tf.summary.scalar('loss', loss)\n",
    "    optimizer = tf.train.AdamOptimizer()\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy_train = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "    accuracy_test = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "    \n",
    "    accuracy_train_ = tf.summary.scalar('accuracy_train', accuracy_train)\n",
    "    accuracy_test_ = tf.summary.scalar('accuracy_test', accuracy_test)\n",
    "\n",
    "with tf.name_scope(\"init_and_save\"):\n",
    "    init = tf.global_variables_initializer()\n",
    "    saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Last batch accuracy: 0.67 Test accuracy: 0.5866\n",
      "1 Last batch accuracy: 0.77 Test accuracy: 0.7573\n",
      "2 Last batch accuracy: 0.88 Test accuracy: 0.8325\n",
      "3 Last batch accuracy: 0.88 Test accuracy: 0.8722\n",
      "4 Last batch accuracy: 0.91 Test accuracy: 0.8758\n",
      "5 Last batch accuracy: 0.92 Test accuracy: 0.9081\n",
      "6 Last batch accuracy: 0.98 Test accuracy: 0.9014\n",
      "7 Last batch accuracy: 0.97 Test accuracy: 0.9226\n",
      "8 Last batch accuracy: 0.97 Test accuracy: 0.9126\n",
      "9 Last batch accuracy: 0.97 Test accuracy: 0.9188\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "batch_size = 100\n",
    "\n",
    "now = datetime.now()\n",
    "logdir = \"tf_logs/\" + now.strftime(\"3_conv_layers_%Y%m%d-%H%M%S\") + \"/\"\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    merged = tf.summary.merge([accuracy_train_,loss_])\n",
    "    tf_tensorboard_writer = tf.summary.FileWriter('./'+logdir, sess.graph)    \n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})       \n",
    "        print(epoch, \"Last batch accuracy:\", accuracy_train.eval(feed_dict={X: X_batch, y: y_batch}), \"Test accuracy:\", accuracy_test.eval(feed_dict={X: X_test, y: y_test}))\n",
    "        \n",
    "        summary_str = sess.run(merged, feed_dict={X: X_batch, y: y_batch})\n",
    "        test_summary_str = sess.run(accuracy_test_, feed_dict={X: X_test, y: y_test})\n",
    "        tf_tensorboard_writer.add_summary(summary_str, epoch) \n",
    "        tf_tensorboard_writer.add_summary(test_summary_str, epoch) \n",
    "        save_path = saver.save(sess, MODEL_PATH + \"model3conv\")\n",
    "        \n",
    "tf_tensorboard_writer.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing rotation and zoom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 576x3600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "samples_to_show = 5\n",
    "plt.figure(figsize=(8,50)) # not shown in the book\n",
    "X_reshaped = tf.reshape(X_train, shape=[-1, height, width])\n",
    "with tf.Session() as sess:\n",
    "    X_reshaped = X_reshaped.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAb0AAABpCAYAAACu9v3JAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAADZlJREFUeJzt3WeMFEQbwPE/ryKKXSJYomJviAYVuyFARCA2sIsVsRewYItYAEUNARQUNdiisaNGY+y9G1tQKSqCgpESUYMF6/vhzczOvre0u73dvZv/79Pk2du9Ydi7uXl25pkW//77L5Ik5eA/1e6AJEmV4qQnScqGk54kKRtOepKkbDjpSZKy4aQnScqGk54kKRtOepKkbDjpSZKysWKFv5/lXxavRT2f55gunmNafo5p+Tmm5bfYMXWlJ0nKhpOeJCkbTnqSpGw46UmSsuGkJ0nKhpOeJCkbTnqSpGw46UmSsuGkJ0nKRqUrsigT3377bWyPGTMGgFGjRsXYoEGDADj33HNjbKONNqpQ7yTlypWeJCkbTnqSpGy0+PffitYsrUqB1H/++Se2Fy1atMSvvfvuuwH45ZdfYuzzzz8HYPTo0TF26aWXAjB27NgYW2WVVQAYOXJkjJ1++unL2s0mX3R29uzZsb3jjjvG9o8//rjY56y99tqxPW/evHJ3qcmPaUNNnjwZgO7du8fYxx9/DMC6665bn5fMakxvv/12AE477bQYC79Ppk6dGmNbbbVVQ75NVmNaIRacliSpSW9k+emnn2L777//BuCTTz6Jseeeew4oXmncdttty/192rdvD8D5558fYxMmTABgzTXXjLF99tkHgK5duy7392jKZs6cCUCXLl1ibMGCBbHdosX//uhKx6pVq1YAzJ07N8amT58OwCabbBJjK6ywQvk7XCZffPFFbId/b+fOnavVnZLeffddALp161blnjQdL774Ymyfd955APznP3XXB+F9rabFlZ4kKRtOepKkbDTJ9OasWbMA2GmnnWIsTaeVQ5rOCKnMsFEFoH///gC0bds2xlZbbTWg3hsEmoQ///wTKKQ0Afbff3+g+GxeKen/1/DhwwHYe++9Y2zLLbcEilPQYZxrUZoGmzJlClAb6c10c1pIwU6bNq1a3Wly0rH6/fffq9iT2jRjxozYvuuuuwB45plnYuz999+v85z77rsvtsN53Oeffz7GTjjhBKDwUVJjcqUnScpGk1zptWnTBoB27drF2PKu9Pbbb786rwcwceJEoLDRAoo3aOTuwgsvBIqPaiyrV199NbbDkZBDDjkkxsLYf/TRRw3pYsXceOONsZ2+n6pt4cKFsX3ttdcCxZVvmnMmoiHC0aQrr7yyzmOdOnWK7bBBbtVVV61Iv2rFm2++CcDhhx8eY3PmzAGKswt9+vSJ7ZD96devX53XS58TjiuNGzeujD0uzZWeJCkbTnqSpGw0yfRm2FASPkQFeOSRRwDYY489Yqxv3751nhs2TjzxxBMxttJKK8X2999/DxSKJKt4g8q9994LFKcmgjRVmY59SG2kBaW33XZbAC666KIYC/+HFa4SVG/hbGitSauHBGG8VezLL7+M7V69egHwww8/1Pm6ESNGxHZ63rS5ClVn0k0rvXv3BorT5wcffDAAw4YNi7GwIQ0KPyMnnXRSjD3wwAN1vt+ee+5Zhl4vG1d6kqRsNJvam6GmZrpqC/Uxr7/++hh7+eWXAdh3330bqyv1VXP190ItzaXV0TzmmGOAQp1CKGwKAPjwww8BOPLII2OsdevWdV4nVF9JNwh89tlnQL2vHWqUMf3uu++A4nqLJ598MlBcn7VaevbsGdvPPvssAF999VWMbbrppg15+Zp7nzbExRdfHNs33HBDncfDpoyHH364MbtRc2MajuP06NGjzmNHHHFEbN9xxx1A8ca/VNi8VqoiUFp5adKkSUDp3wv1ZO1NSZKc9CRJ2WiSG1lKKbW8Tq+tCcLZqlAcGiwcm5o/f35sX3fddUDxGchwNjJNkYXrk9LUclp9JW0vi19//TW2Q8opPRNXbeGcVtrPWhDOPoZUUSo9i5q7Uu8vKFRhSsdq6NChletYlaU/Y4MGDQKKfzcOGTIEKN58tri0ZjBw4MDFPvbggw/GdhnTmkvlSk+SlI1ms9IrJfyV8d5778XYY489BhQ2SAB06NChsh2rQX/99RcAF1xwQYyF4wnpFu2wMWKLLbaIsVCPszF8/fXXjfba9fXpp5/WiS3varYxXHbZZUBhow1Ax44dgeJVeK7CJqyDDjpoiV+XVmTZZpttGrNLNWH8+PFAYXUHhRVcuvnskksuAaBly5Z1XiP8/oDi691C7dd0w2RYUe6yyy4N7nt9uNKTJGXDSU+SlI1mnd4MKZ30qppw/iRNcYSqAgB77bUXUFxdJIeNLt988w1QSGmm3nnnndhOz6YF6ZVLudptt90a/XuEs6gAH3zwAVD83k43BgQhlbTyyis3cu9q3+uvvw7AW2+9VfLxww47DChcc9OcpVcmhc066e+5kNYM5/AWJ1SvSc/uhbPQqVNPPTW2BwwYUI8el48rPUlSNpr1Si9YZ511YjtsxAgXn0JxFY3QTv/CCXUkwyWxzdGZZ54JFH/gHFa7pVZ3jSHU+0sv8G0qdThLVaopJWwyCf9WKFStSDft/PHHHwDcdNNNMZbW+gxVa9IrjcJqLt1YlHvNzfRC0+OPP77O4wcccEBsh4pCOayK0/dSuB4oNWrUKKBwDAYKtXHTjMLbb78NwM8//xxj6YoxtEPFIqj+pipXepKkbDjpSZKykUV6M9W5c2eg+Jxeej4lFJZNr8IIxXrDreEAq6++eqP2sxLSG8pfe+01oDg1ET7Yr5SQ1kz7UK2zPEsSqkek/TzwwAMB2HrrrZf43JAOStO2K674vx/DNH0eNsak5ybTKkLhXGBanDsU5U5TUrnekh7SzbvvvvsSvy49b5rTTeihuDvAeuutBxSuVYPCR0JL28S38cYbA7DWWmvFWHoVWajglN48X22u9CRJ2XDSkyRlI7v0ZrD++uvHdnoDe7h1unv37jE2fPhwAKZOnRpjpc5ENTXpWZ1wBmyDDTaIsXBTcmMIZYtKFZI+9NBDYzvciVhLrr76agA233zzGHvllVeW6bnhVumjjz46xkKKrT733D399NOxHdJTOZTOWpqRI0cCxTuBS0mLJ+ck3aH6xhtvAMWp4Hnz5gGw3Xbbxdixxx4LwHHHHRdjISUcHoPi9GYoRl9LXOlJkrKR7Uovlf7V06VLF6D4g96wKnn88cdjLKz6lrZxoalJx6Lc5xLTorS33HILAIMHD46x9u3bA4XCyVD9Mz1Lkp77KnUGrBKeeuqpOrF0E1ZOZs+eHdvhTFkpJ554YmznutEnFX7u0o0syyoUlE5/N6ar61rMOrjSkyRlw0lPkpSNbNOb6Z1jEydOjO1wjipNxQW77rprbFeqNFelpR9Il0tIO4Wb2AFuvvlmoDjVFMpAqWH69OlT7S5URXqmc/78+XUe79GjBwBjx46tWJ+au7AZLk1ppmf7evbsWfE+LY0rPUlSNrJY6YXttwDjxo0D4M4774yxWbNmLfH5YVNL+MAXmsd1Q2lVkNBOj29cfvnl9X7t+++/P7bPPvtsABYsWBBj55xzDlAobCs11Ny5c2O71FGFcDyhljdHNTU77LBDtbuw3FzpSZKy4aQnScpGs0tvLly4MLaffPJJoFBBA2DatGnL9Dpdu3aN7REjRgCw8847l6OLNaPUvVdpqjeMW//+/WMsFNpOC3bfeuutQOFmaoAZM2bEdqhcEm5jhkJ6U+UTUtQzZ86Msc0226xa3amYUJQ7vaOwlI4dO1aiO1mZNGlStbuw3FzpSZKy0aRXeukVKqHeW79+/WIsvTpnSdLbp6+66iqg+HhCc9i0sqzSG5XDSm/ChAkxFq4cWdpfeOlW5XBL/VlnnVW2fqqu8D5d2oqnOShVfSXdvNKqVSsArrjiihjL6eqgSpk+fXq1u7DcXOlJkrLhpCdJykaTSW/+9ttvsT1w4ECgcCUGwJQpU5bpdXr16gXAkCFDYizcQg3QsmXLBvWzKdl+++1jO1yl9MILL9T5unRzS5pWCtq2bQsUXyPSkDN+apiXXnoptrt161bFnjSedMNaqfdkOFOb69VBldK5c2egOKW+tOucqq22eydJUhnV5Eov3e5+zTXXAMUrkHRL9pK0bt0agKFDh8bYGWecAViVAWCNNdaI7bAZ4J577omxJR0rGDZsWGwPGDAAgDZt2pS7i1oOaYUdqRLCZdwdOnSIscmTJ8f2nDlzgPpdkNxYXOlJkrLhpCdJykZNpjcfffTR2E7PiP2/Tp06xfZRRx0FwIorFv5Jp5xyClB8G7hKC7ekh/Tv/7dVm/r27Rvb48ePr2JPKmvDDTeM7d69ewOFCkyqvNGjR8d2uMIJYPDgwUDxdU7t2rWrXMdKcKUnScpGiwp/+O0n7YtX37IvjuniOabl55iWX5Mf00WLFsV2ejH0Qw89BBQ2uwGMGTMGaPTNhIsdU1d6kqRsOOlJkrJherN2NPkURw1yTMvPMS2/ZjWmaaozXMuWnpUOFXQaeUOL6U1Jklzp1Y5m9ddejXBMy88xLT/HtPxc6UmS5KQnScpGpdObkiRVjSs9SVI2nPQkSdlw0pMkZcNJT5KUDSc9SVI2nPQkSdlw0pMkZcNJT5KUDSc9SVI2nPQkSdlw0pMkZcNJT5KUDSc9SVI2nPQkSdlw0pMkZcNJT5KUDSc9SVI2nPQkSdlw0pMkZcNJT5KUDSc9SVI2nPQkSdlw0pMkZeO/N2viXar0jVIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1080x3600 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,50)) # not shown in the book\n",
    "for iteration in range(samples_to_show):\n",
    "    plt.subplot(samples_to_show, 10, iteration + 1)\n",
    "    plot_image(X_reshaped[iteration])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x3600 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.ndimage import rotate\n",
    "plt.figure(figsize=(15,50)) # not shown in the book\n",
    "degrees = 10\n",
    "for iteration in range(samples_to_show):\n",
    "    plt.subplot(samples_to_show, 10, iteration + 1)\n",
    "    plot_image(rotate(X_reshaped[iteration], 20, reshape=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zoom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x3600 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,50)) # not shown in the book\n",
    "for iteration in range(samples_to_show):\n",
    "    plt.subplot(samples_to_show, 10, iteration + 1)\n",
    "    plot_image(clipped_zoom(X_reshaped[iteration], 0.7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Increasing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_zoom1 = X_reshaped.copy()\n",
    "X_train_zoom2 = X_reshaped.copy()\n",
    "X_train_rotate1 = X_reshaped.copy()\n",
    "X_train_rotate2 = X_reshaped.copy()\n",
    "\n",
    "for iteration in range(nb_samples_taken):\n",
    "    X_train_zoom1[iteration] = clipped_zoom(X_train_zoom[iteration], 0.95)\n",
    "    X_train_zoom2[iteration] = clipped_zoom(X_train_zoom[iteration], 1.05)\n",
    "\n",
    "for iteration in range(nb_samples_taken):\n",
    "    X_train_rotate1[iteration] = rotate(X_train_rotate1[iteration], 8, reshape=False)    \n",
    "    X_train_rotate2[iteration] = rotate(X_train_rotate2[iteration], -8, reshape=False)\n",
    "\n",
    "X_train_artificially_increased = np.concatenate((X_reshaped, X_train_zoom1, X_train_zoom2,X_train_rotate1,X_train_rotate2), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300000, 784)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_artificially_increased = X_train_artificially_increased.astype(np.float32).reshape(-1, n_inputs)\n",
    "X_train_artificially_increased.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300000,)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_artificially_increased = np.concatenate((y_train,y_train,y_train,y_train,y_train), axis=0)\n",
    "y_train_artificially_increased.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training model with dataset artificially_increased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Last batch accuracy: 0.83 Test accuracy: 0.8443\n",
      "1 Last batch accuracy: 0.9 Test accuracy: 0.924\n",
      "2 Last batch accuracy: 0.95 Test accuracy: 0.9351\n",
      "3 Last batch accuracy: 0.97 Test accuracy: 0.9331\n",
      "4 Last batch accuracy: 0.96 Test accuracy: 0.9448\n",
      "5 Last batch accuracy: 0.99 Test accuracy: 0.9459\n",
      "6 Last batch accuracy: 1.0 Test accuracy: 0.9441\n",
      "7 Last batch accuracy: 1.0 Test accuracy: 0.9479\n",
      "8 Last batch accuracy: 1.0 Test accuracy: 0.9525\n",
      "9 Last batch accuracy: 1.0 Test accuracy: 0.9544\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "batch_size = 100\n",
    "\n",
    "now = datetime.now()\n",
    "logdir = \"tf_logs/\" + now.strftime(\"3_conv_DatasetIncreasedArt__%Y%m%d-%H%M%S\") + \"/\"\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    merged = tf.summary.merge([accuracy_train_,loss_])\n",
    "    tf_tensorboard_writer = tf.summary.FileWriter('./'+logdir, sess.graph)\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train_artificially_increased, y_train_artificially_increased, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})       \n",
    "        print(epoch, \"Last batch accuracy:\", accuracy_train.eval(feed_dict={X: X_batch, y: y_batch}), \"Test accuracy:\", accuracy_test.eval(feed_dict={X: X_test, y: y_test}))\n",
    "        \n",
    "        summary_str = sess.run(merged, feed_dict={X: X_batch, y: y_batch})\n",
    "        test_summary_str = sess.run(accuracy_test_, feed_dict={X: X_test, y: y_test})\n",
    "        tf_tensorboard_writer.add_summary(summary_str, epoch) \n",
    "        tf_tensorboard_writer.add_summary(test_summary_str, epoch) \n",
    "        save_path = saver.save(sess, MODEL_PATH + \"with_dataset_artificially_increased/model3conv\")\n",
    "        \n",
    "tf_tensorboard_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Better network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "conv1_fmaps = 6\n",
    "conv1_ksize = 6\n",
    "conv1_stride = 1\n",
    "\n",
    "conv2_fmaps = 12\n",
    "conv2_ksize = 5\n",
    "conv2_stride = 2\n",
    "\n",
    "pool1_fmaps = conv2_fmaps\n",
    "\n",
    "conv3_fmaps = 24\n",
    "conv3_ksize = 4\n",
    "conv3_stride = 2\n",
    "\n",
    "conv4_fmaps = 48\n",
    "conv4_ksize = 4\n",
    "conv4_stride = 2\n",
    "\n",
    "pool2_fmaps = conv4_fmaps\n",
    "\n",
    "n_fc1 = 200\n",
    "n_outputs = 10\n",
    "\n",
    "in_training_mode = tf.placeholder_with_default(False, shape=[], name='training')\n",
    "fc1_dropout_rate = 0.5\n",
    "\n",
    "with tf.name_scope(\"inputs\"):\n",
    "    X = tf.placeholder(tf.float32, shape=[None, n_inputs], name=\"X\")\n",
    "    X_reshaped = tf.reshape(X, shape=[-1, height, width, channels])\n",
    "    X_BN = tf.layers.batch_normalization(X_reshaped, momentum=0.9, training=in_training_mode)\n",
    "    y = tf.placeholder(tf.int32, shape=[None], name=\"y\")\n",
    "\n",
    "conv1 = tf.layers.conv2d(X_BN, filters=conv1_fmaps, kernel_size=conv1_ksize,\n",
    "                         strides=conv1_stride, padding=\"SAME\",\n",
    "                         activation=None, name=\"conv1\")\n",
    "conv1_BN = tf.layers.batch_normalization(conv1, momentum=0.9, training=in_training_mode)\n",
    "conv1_relu = tf.nn.relu(conv1_BN) \n",
    "\n",
    "conv2 = tf.layers.conv2d(conv1_relu, filters=conv2_fmaps, kernel_size=conv2_ksize,\n",
    "                         strides=conv2_stride, padding=\"SAME\",\n",
    "                         activation=None, name=\"conv2\")\n",
    "conv2_BN = tf.layers.batch_normalization(conv2, momentum=0.9, training=in_training_mode)\n",
    "conv2_relu = tf.nn.relu(conv2_BN) \n",
    "\n",
    "pool1 = tf.nn.max_pool(conv2_relu, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"VALID\", name=\"conv3\")\n",
    "    \n",
    "\n",
    "conv3 = tf.layers.conv2d(pool1, filters=conv3_fmaps, kernel_size=conv3_ksize,\n",
    "                         strides=conv3_stride, padding=\"SAME\",\n",
    "                         activation=None, name=\"conv3\")\n",
    "conv3_BN = tf.layers.batch_normalization(conv3, momentum=0.9, training=in_training_mode)\n",
    "conv3_relu = tf.nn.relu(conv3_BN) \n",
    "\n",
    "conv4 = tf.layers.conv2d(conv3_relu, filters=conv4_fmaps, kernel_size=conv4_ksize,\n",
    "                         strides=conv4_stride, padding=\"SAME\",\n",
    "                         activation=None, name=\"conv4\")\n",
    "conv4_BN = tf.layers.batch_normalization(conv4, momentum=0.9, training=in_training_mode)\n",
    "conv4_relu = tf.nn.relu(conv4_BN) \n",
    "\n",
    "with tf.name_scope(\"pool2\"):\n",
    "    pool2 = tf.nn.max_pool(conv4_relu, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"VALID\")\n",
    "    pool2_flat = tf.reshape(pool2, shape=[-1, pool2_fmaps * int(pool2.shape[1]) * int(pool2.shape[1])])\n",
    "    \n",
    "\n",
    "with tf.name_scope(\"fc1\"):\n",
    "    fc1 = tf.layers.dense(pool2_flat, n_fc1, activation=tf.nn.relu, name=\"fc1\")\n",
    "    fc1_drop = tf.layers.dropout(fc1, fc1_dropout_rate, training=in_training_mode)   \n",
    "\n",
    "\n",
    "with tf.name_scope(\"output\"):\n",
    "    logits = tf.layers.dense(fc1, n_outputs, name=\"output\")\n",
    "    Y_proba = tf.nn.softmax(logits, name=\"Y_proba\")\n",
    "\n",
    "update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "with tf.control_dependencies(update_ops):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=y)\n",
    "    loss = tf.reduce_mean(xentropy)\n",
    "    loss_ = tf.summary.scalar('loss', loss)\n",
    "    optimizer = tf.train.AdamOptimizer()\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy_train = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "    accuracy_test = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "    \n",
    "    accuracy_train_ = tf.summary.scalar('accuracy_train', accuracy_train)\n",
    "    accuracy_test_ = tf.summary.scalar('accuracy_test', accuracy_test)\n",
    "\n",
    "with tf.name_scope(\"init_and_save\"):\n",
    "    init = tf.global_variables_initializer()\n",
    "    saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 20\n",
    "batch_size = 100\n",
    "\n",
    "now = datetime.now()\n",
    "logdir = \"tf_logs/\" + now.strftime(\"4conv_DatasetIncreasedArt__%Y%m%d-%H%M%S\") + \"/\"\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    merged = tf.summary.merge([accuracy_train_,loss_])\n",
    "    tf_tensorboard_writer = tf.summary.FileWriter('./'+logdir, sess.graph)    \n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train_artificially_increased, y_train_artificially_increased, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch, in_training_mode: True})       \n",
    "        print(epoch, \"Last batch accuracy:\", accuracy_train.eval(feed_dict={X: X_batch, y: y_batch}), \"Test accuracy:\", accuracy_test.eval(feed_dict={X: X_test, y: y_test}))\n",
    "        \n",
    "        summary_str = sess.run(merged, feed_dict={X: X_batch, y: y_batch})\n",
    "        test_summary_str = sess.run(accuracy_test_, feed_dict={X: X_test, y: y_test})\n",
    "        tf_tensorboard_writer.add_summary(summary_str, epoch) \n",
    "        tf_tensorboard_writer.add_summary(test_summary_str, epoch) \n",
    "        save_path = saver.save(sess, MODEL_PATH + \"with_dataset_artificially_increased/model4conv\")\n",
    "        \n",
    "tf_tensorboard_writer.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
